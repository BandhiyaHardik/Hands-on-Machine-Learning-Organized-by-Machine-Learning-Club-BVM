{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsAzxPJnpg62"
   },
   "source": [
    "# **Hands on Machine Learning : Build While you Learn**\n",
    "\n",
    "Week 2 : Shaping Data for ML: Clean, Transform and Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X37Pzapktjvp"
   },
   "source": [
    "Specially for you guys:\n",
    "\n",
    "Github Repo:\n",
    "\n",
    "In this Repo you will Find:\n",
    "1. week 1 Python Codes\n",
    "2. Learning Resources of week 1\n",
    "3. Small assignments for your practice and you will submit it through the contribution\n",
    "4. You will get a video in repo on how to contribute to the project\n",
    "\n",
    "So By The end of our week 4 you will not only complete the basics of ML but you will also have your own First PR and Pull Issues Merged into our repo. You will learn about Git & Github along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_LbWXo_u6Ux"
   },
   "source": [
    "# **What is seaborn?**\n",
    "\n",
    "\n",
    "*   Seaborn is a Python library built on top of Matplotlib, designed for beautiful, easy-to-use visualizations.\n",
    "*   Compared to Matplotlib, it’s more high-level\n",
    "*   It helps in spotting patterns, trends, and correlations in data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# **Why Data Preparation ?**\n",
    "\n",
    "If data is messy then the results will be messy as well. No matter how good the Algorithm is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNYSjQFkvmwQ"
   },
   "source": [
    "# **How do we find datasets ?**\n",
    "\n",
    "Most of the People use Kaggle for finding datasets.\n",
    "\n",
    "[Kaggle Link](https://www.kaggle.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "executionInfo": {
     "elapsed": 2366,
     "status": "error",
     "timestamp": 1757491400824,
     "user": {
      "displayName": "Hardik Bandhiya",
      "userId": "06050270412149043970"
     },
     "user_tz": -330
    },
    "id": "QalROvvOpFg5",
    "outputId": "359e9294-297a-4b7b-fbd6-b471123ec6bd"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'messy_songs_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1376634459.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Step 2: Load Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"messy_songs_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Preview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'messy_songs_dataset.csv'"
     ]
    }
   ],
   "source": [
    "# Week 2: Shaping Data for ML – Cleaning, Transforming, Preparing\n",
    "\n",
    "# Step 1: Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 2: Load Dataset\n",
    "df = pd.read_csv(\"messy_songs_dataset.csv\")\n",
    "\n",
    "# Preview\n",
    "print(\"First 5 rows:\\n\", df.head())\n",
    "print(\"\\nDataset Info:\\n\")\n",
    "df.info()\n",
    "print(\"\\nSummary:\\n\", df.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 94,
     "status": "aborted",
     "timestamp": 1757491400827,
     "user": {
      "displayName": "Hardik Bandhiya",
      "userId": "06050270412149043970"
     },
     "user_tz": -330
    },
    "id": "FZCFLmo_z4Rm"
   },
   "outputs": [],
   "source": [
    "# Step 3: Identify Issues\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "print(\"\\nDuplicate Rows:\", df.duplicated().sum())\n",
    "\n",
    "# Example: Check unique categories in a column\n",
    "print(\"\\nUnique Languages:\\n\", df['Language'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pU7ohHH1pmA"
   },
   "source": [
    "# **What is Data Cleaning?**\n",
    "\n",
    "1. Removing missing values\n",
    "2. Fixing duplicates\n",
    "3. Correcting inconsistencies\n",
    "4. Making sure numbers are actually numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "aborted",
     "timestamp": 1757491400828,
     "user": {
      "displayName": "Hardik Bandhiya",
      "userId": "06050270412149043970"
     },
     "user_tz": -330
    },
    "id": "JTjuT5Wv0Ahw"
   },
   "outputs": [],
   "source": [
    "# Step 4: Cleaning Data\n",
    "\n",
    "# Fix category casing\n",
    "df['Language'] = df['Language'].str.strip().str.lower()\n",
    "\n",
    "# Handle missing values (example: fill with mean)\n",
    "df['Streams'] = df['Streams'].fillna(df['Streams'].mean())\n",
    "\n",
    "# Clean messy ratings (remove * and convert to float)\n",
    "df['Rating'] = df['Rating'].replace(r'[^0-9.]', '', regex=True).astype(float)\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# After cleaning\n",
    "print(\"\\nCleaned Data Info:\\n\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kp3u1hBR3qRm"
   },
   "source": [
    "# **What is Data Transformation?**\n",
    "\n",
    "It is Basically Changing data into a form ML can understand.\n",
    "\n",
    "1. Scaling: Bringing numbers to the same range (like converting height from cm and inches into one standard unit).\n",
    "2. Encoding: Converting categories (like Hindi, English, Japanese) into numbers so ML can read them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 65,
     "status": "aborted",
     "timestamp": 1757491400847,
     "user": {
      "displayName": "Hardik Bandhiya",
      "userId": "06050270412149043970"
     },
     "user_tz": -330
    },
    "id": "c5onzNS50FSY"
   },
   "outputs": [],
   "source": [
    "# Step 5: Visualization Before vs After Cleaning\n",
    "\n",
    "# Example: Distribution of Streams\n",
    "sns.histplot(df['Streams'], kde=True, color=\"blue\")\n",
    "plt.title(\"Distribution of Streams (Cleaned)\")\n",
    "plt.show()\n",
    "\n",
    "# Example: Countplot of Languages\n",
    "sns.countplot(x='Language', data=df)\n",
    "plt.title(\"Songs by Language\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rbe1V98Y2Arq"
   },
   "source": [
    "# **What is Sklearn?**\n",
    "\n",
    "\n",
    "*   Scikit-learn is one of the most popular Python libraries for Machine Learning.\n",
    "*   It provides simple tools for Data preprocessing(cleaning, encoding, scaling), Splitting data into training/testing sets, ML algorithms (linear regression, decision trees, KNN, SVM, etc.),Model evaluation (accuracy, confusion matrix, cross-validation).\n",
    "\n",
    "\n",
    "\n",
    "# **What is Data Preparation?**\n",
    "\n",
    "1. Splitting data into train and test\n",
    "2. Feature selection: choosing the right “ingredients” that matter most.\n",
    "3. Making sure everything is tidy, consistent, and ready for the ML model.\n",
    "\n",
    "# **Types of Machine Learning**\n",
    "\n",
    "\n",
    "\n",
    "*  **Supervised Learning** : You train the model with input + output labels.\n",
    "\n",
    "\n",
    "1.   Model learns the mapping → predicts output for new input.\n",
    "2.   Ex: Predicting house prices (input: size, location → output: price).\n",
    "3.   Ex: A teacher gives you questions + correct answers to practice.\n",
    "4.   If I have to say in one line then \"Learn with supervision (labels).\"\n",
    "\n",
    "\n",
    "*   **Unsupervised Learning**\n",
    "\n",
    "\n",
    "1.  You only provide inputs (no labels).\n",
    "2.  Model finds patterns, groups, or structure in data.\n",
    "3.  Ex: Customer segmentation (grouping people by buying habits).\n",
    "4.  Ex: You’re given a pile of books and asked to organize them without knowing subjects.\n",
    "5.   If I have to say in one line then \"Learning without a teacher.\"\n",
    "\n",
    "\n",
    "*   **Reinforcement Learning**\n",
    "\n",
    "\n",
    "1.   The model (agent) learns by trial and error with rewards & penalties.\n",
    "2.   Maximize reward by learning the best actions.\n",
    "3.   Ex: A dog learns tricks if it does well, you give it a treat.\n",
    "4.   If I have to say in one line then \"Learning from feedback.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPbDrwa5W9JkMMoINqRlcJ8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
