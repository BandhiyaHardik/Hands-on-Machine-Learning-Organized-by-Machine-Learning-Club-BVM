{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPbDrwa5W9JkMMoINqRlcJ8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Hands on Machine Learning : Build While you Learn**\n","\n","Week 2 : Shaping Data for ML: Clean, Transform and Prepare"],"metadata":{"id":"TsAzxPJnpg62"}},{"cell_type":"markdown","source":["Specially for you guys:\n","\n","Github Repo:\n","\n","In this Repo you will Find:\n","1. week 1 Python Codes\n","2. Learning Resources of week 1\n","3. Small assignments for your practice and you will submit it through the contribution\n","4. You will get a video in repo on how to contribute to the project\n","\n","So By The end of our week 4 you will not only complete the basics of ML but you will also have your own First PR and Pull Issues Merged into our repo. You will learn about Git & Github along the way."],"metadata":{"id":"X37Pzapktjvp"}},{"cell_type":"markdown","source":["# **What is seaborn?**\n","\n","\n","*   Seaborn is a Python library built on top of Matplotlib, designed for beautiful, easy-to-use visualizations.\n","*   Compared to Matplotlib, it’s more high-level\n","*   It helps in spotting patterns, trends, and correlations in data.\n","\n","\n","\n","\n","\n","\n","# **Why Data Preparation ?**\n","\n","If data is messy then the results will be messy as well. No matter how good the Algorithm is."],"metadata":{"id":"n_LbWXo_u6Ux"}},{"cell_type":"markdown","source":["# **How do we find datasets ?**\n","\n","Most of the People use Kaggle for finding datasets.\n","\n","[Kaggle Link](https://www.kaggle.com/)"],"metadata":{"id":"lNYSjQFkvmwQ"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"QalROvvOpFg5","executionInfo":{"status":"error","timestamp":1757491400824,"user_tz":-330,"elapsed":2366,"user":{"displayName":"Hardik Bandhiya","userId":"06050270412149043970"}},"outputId":"359e9294-297a-4b7b-fbd6-b471123ec6bd"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'messy_songs_dataset.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1376634459.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Step 2: Load Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"messy_songs_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Preview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'messy_songs_dataset.csv'"]}],"source":["# Week 2: Shaping Data for ML – Cleaning, Transforming, Preparing\n","\n","# Step 1: Importing libraries\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Step 2: Load Dataset\n","df = pd.read_csv(\"messy_songs_dataset.csv\")\n","\n","# Preview\n","print(\"First 5 rows:\\n\", df.head())\n","print(\"\\nDataset Info:\\n\")\n","df.info()\n","print(\"\\nSummary:\\n\", df.describe(include='all'))\n"]},{"cell_type":"code","source":["# Step 3: Identify Issues\n","print(\"\\nMissing Values:\\n\", df.isnull().sum())\n","print(\"\\nDuplicate Rows:\", df.duplicated().sum())\n","\n","# Example: Check unique categories in a column\n","print(\"\\nUnique Languages:\\n\", df['Language'].unique())\n"],"metadata":{"id":"FZCFLmo_z4Rm","executionInfo":{"status":"aborted","timestamp":1757491400827,"user_tz":-330,"elapsed":94,"user":{"displayName":"Hardik Bandhiya","userId":"06050270412149043970"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **What is Data Cleaning?**\n","\n","1. Removing missing values\n","2. Fixing duplicates\n","3. Correcting inconsistencies\n","4. Making sure numbers are actually numbers"],"metadata":{"id":"2pU7ohHH1pmA"}},{"cell_type":"code","source":["# Step 4: Cleaning Data\n","\n","# Fix category casing\n","df['Language'] = df['Language'].str.strip().str.lower()\n","\n","# Handle missing values (example: fill with mean)\n","df['Streams'] = df['Streams'].fillna(df['Streams'].mean())\n","\n","# Clean messy ratings (remove * and convert to float)\n","df['Rating'] = df['Rating'].replace(r'[^0-9.]', '', regex=True).astype(float)\n","\n","# Drop duplicates\n","df = df.drop_duplicates()\n","\n","# After cleaning\n","print(\"\\nCleaned Data Info:\\n\")\n","df.info()\n"],"metadata":{"id":"JTjuT5Wv0Ahw","executionInfo":{"status":"aborted","timestamp":1757491400828,"user_tz":-330,"elapsed":48,"user":{"displayName":"Hardik Bandhiya","userId":"06050270412149043970"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **What is Data Transformation?**\n","\n","It is Basically Changing data into a form ML can understand.\n","\n","1. Scaling: Bringing numbers to the same range (like converting height from cm and inches into one standard unit).\n","2. Encoding: Converting categories (like Hindi, English, Japanese) into numbers so ML can read them."],"metadata":{"id":"Kp3u1hBR3qRm"}},{"cell_type":"code","source":["# Step 5: Visualization Before vs After Cleaning\n","\n","# Example: Distribution of Streams\n","sns.histplot(df['Streams'], kde=True, color=\"blue\")\n","plt.title(\"Distribution of Streams (Cleaned)\")\n","plt.show()\n","\n","# Example: Countplot of Languages\n","sns.countplot(x='Language', data=df)\n","plt.title(\"Songs by Language\")\n","plt.xticks(rotation=45)\n","plt.show()\n"],"metadata":{"id":"c5onzNS50FSY","executionInfo":{"status":"aborted","timestamp":1757491400847,"user_tz":-330,"elapsed":65,"user":{"displayName":"Hardik Bandhiya","userId":"06050270412149043970"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **What is Sklearn?**\n","\n","\n","*   Scikit-learn is one of the most popular Python libraries for Machine Learning.\n","*   It provides simple tools for Data preprocessing(cleaning, encoding, scaling), Splitting data into training/testing sets, ML algorithms (linear regression, decision trees, KNN, SVM, etc.),Model evaluation (accuracy, confusion matrix, cross-validation).\n","\n","\n","\n","# **What is Data Preparation?**\n","\n","1. Splitting data into train and test\n","2. Feature selection: choosing the right “ingredients” that matter most.\n","3. Making sure everything is tidy, consistent, and ready for the ML model.\n","\n","# **Types of Machine Learning**\n","\n","\n","\n","*  **Supervised Learning** : You train the model with input + output labels.\n","\n","\n","1.   Model learns the mapping → predicts output for new input.\n","2.   Ex: Predicting house prices (input: size, location → output: price).\n","3.   Ex: A teacher gives you questions + correct answers to practice.\n","4.   If I have to say in one line then \"Learn with supervision (labels).\"\n","\n","\n","*   **Unsupervised Learning**\n","\n","\n","1.  You only provide inputs (no labels).\n","2.  Model finds patterns, groups, or structure in data.\n","3.  Ex: Customer segmentation (grouping people by buying habits).\n","4.  Ex: You’re given a pile of books and asked to organize them without knowing subjects.\n","5.   If I have to say in one line then \"Learning without a teacher.\"\n","\n","\n","*   **Reinforcement Learning**\n","\n","\n","1.   The model (agent) learns by trial and error with rewards & penalties.\n","2.   Maximize reward by learning the best actions.\n","3.   Ex: A dog learns tricks if it does well, you give it a treat.\n","4.   If I have to say in one line then \"Learning from feedback.\"\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"Rbe1V98Y2Arq"}},{"cell_type":"code","source":["# Step 6: Simple Model Before vs After Cleaning\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","from sklearn.metrics import mean_squared_error, accuracy_score\n","\n","# Example: Predicting Streams from Rating (Linear Regression)\n","X = df[['Rating']].fillna(0)\n","y = df['Streams']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","linreg = LinearRegression()\n","linreg.fit(X_train, y_train)\n","y_pred = linreg.predict(X_test)\n","\n","print(\"Linear Regression MSE:\", mean_squared_error(y_test, y_pred))\n","\n","# Example: Predicting if song is 'popular' (Logistic Regression)\n","df['Popular'] = (df['Streams'] > df['Streams'].median()).astype(int)\n","\n","X = df[['Rating']].fillna(0)\n","y = df['Popular']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","logreg = LogisticRegression()\n","logreg.fit(X_train, y_train)\n","y_pred = logreg.predict(X_test)\n","\n","print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n"],"metadata":{"id":"vGwMGf_60NxW","executionInfo":{"status":"aborted","timestamp":1757491400850,"user_tz":-330,"elapsed":2925,"user":{"displayName":"Hardik Bandhiya","userId":"06050270412149043970"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Model on Messy Data**\n","\n","1. Let's try running Machine Learning without any cleaning.\n","2. We'll directly feed the raw dataset into Linear Regression and Logistic Regression."],"metadata":{"id":"03RCgd662syJ"}},{"cell_type":"code","source":["# Week 2: Shaping Data for ML\n","# Demo: Using Messy Dataset Without Cleaning\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","from sklearn.metrics import mean_squared_error, accuracy_score\n","\n","# --- Load messy dataset ---\n","# (Use the messy songs dataset you created or Kaggle one)\n","df = pd.read_csv(\"messy_songs_dataset.csv\")\n","\n","print(\"First 5 Rows of Messy Data:\\n\", df.head())\n","print(\"\\nDataset Info (Messy):\\n\")\n","df.info()\n","\n","# --- Try Linear Regression ---\n","# Predict Streams from Rating (without cleaning)\n","X = df[['Rating']]   # contains messy values like '4.5*'\n","y = df['Streams']\n","\n","# Convert errors to NaN and drop them (force model to run)\n","X = pd.to_numeric(X['Rating'], errors='coerce').fillna(0).values.reshape(-1,1)\n","y = pd.to_numeric(y, errors='coerce').fillna(0)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","linreg = LinearRegression()\n","linreg.fit(X_train, y_train)\n","y_pred = linreg.predict(X_test)\n","\n","print(\"\\nLinear Regression (Messy Data) MSE:\", mean_squared_error(y_test, y_pred))\n","\n","# --- Try Logistic Regression ---\n","# Define 'Popular' = 1 if Streams > median else 0\n","df['Popular'] = (pd.to_numeric(df['Streams'], errors='coerce') >\n","                 pd.to_numeric(df['Streams'], errors='coerce').median()).astype(int)\n","\n","X = pd.to_numeric(df['Rating'], errors='coerce').fillna(0).values.reshape(-1,1)\n","y = df['Popular']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","logreg = LogisticRegression()\n","logreg.fit(X_train, y_train)\n","y_pred = logreg.predict(X_test)\n","\n","print(\"Logistic Regression (Messy Data) Accuracy:\", accuracy_score(y_test, y_pred))\n"],"metadata":{"id":"nq9Rqj4S0Tlg","executionInfo":{"status":"aborted","timestamp":1757491400851,"user_tz":-330,"elapsed":2925,"user":{"displayName":"Hardik Bandhiya","userId":"06050270412149043970"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"I9n0ghap2cxZ","executionInfo":{"status":"aborted","timestamp":1757491400852,"user_tz":-330,"elapsed":2926,"user":{"displayName":"Hardik Bandhiya","userId":"06050270412149043970"}}},"execution_count":null,"outputs":[]}]}